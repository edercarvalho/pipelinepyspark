{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Teste_DE_SAS_v1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO+XO+F2jqngNBEMN3ZpWV/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edercarvalho/pipelinepyspark/blob/master/Teste_DE_SAS_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ2tgnwPadrj",
        "colab_type": "text"
      },
      "source": [
        "# Pipeline Engenharia de Dados - Teste SAS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk8dLk5BdyEr",
        "colab_type": "text"
      },
      "source": [
        "**Info**\n",
        "\n",
        "Este script foi criado utilizando Python 3.6 com Spark 2.4.5 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m9_jmbpgfmR",
        "colab_type": "text"
      },
      "source": [
        "**Iniciar**\n",
        "\n",
        "Para começar precisamos configurar o ambiente instalando os pacotes e biblioteca necessarios para o funcionamento do script.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91mrA8zCgn5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf8c6_YJiFAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configurando as variaveis de Ambiente \n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tlvQIk2iU33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Iniciando o Spark\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "# Importando pacotes necessario para criação do contexo de DataLake utilizando SQL e HIVE que sera usado depois\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession,HiveContext\n",
        "\n",
        "#Inicializando o Hive\n",
        "SparkContext.setSystemProperty(\"hive.metastore.uris\", \"thrift://nn1:9083\")\n",
        "\n",
        "# Criando a Sessão Spark\n",
        "spark = (SparkSession\n",
        "       .builder\n",
        "       .master(\"local[*]\")\n",
        "       .enableHiveSupport()\n",
        "       .getOrCreate())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ1IJ2_BjBbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importando o arquivo data_question.json que iremos trabalhar para dentro do colab\n",
        "from google.colab import files\n",
        "\n",
        "#Ira abrir a opção de você importar o aquivo , vou deixar aqui github para você fazer o download\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_nnp3LBmGoV",
        "colab_type": "text"
      },
      "source": [
        "# **Criando o Schema**\n",
        "\n",
        "Eu escolhi criar o Schema utilizando Spark SQL **StructType** e **StructField** devido ser mais simples e trabalhar bem com Jsons complexo e com campos aninhados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6hY_YYwmD7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importantado as Estruturas para criação do Schema\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "# Criando o Schema\n",
        "schema_questions = StructType([\n",
        "    StructField(\"answer_key\", IntegerType(), True),\n",
        "    StructField(\"difficulty\", StringType(), True),\n",
        "    StructField(\"grade\", LongType(), True),\n",
        "    StructField(\"id\", IntegerType(), True),\n",
        "    StructField(\"lecture\", IntegerType(), True),\n",
        "    StructField(\"options\", ArrayType(\n",
        "            StructType([\n",
        "                StructField(\"description\",StringType() , True),\n",
        "                StructField(\"id\", IntegerType(), True),\n",
        "                                      ])\n",
        "        ), True), \n",
        "StructField(\"properties\", ArrayType(\n",
        "            StructType([\n",
        "                StructField(\"id\", StringType(), True),\n",
        "                StructField(\"key\",StringType() , True),\n",
        "                StructField(\"value\", IntegerType(), True)\n",
        "                      ])\n",
        "        ), True),\n",
        "StructField(\"skill\", StructType([\n",
        "        StructField(\"code\", LongType(), True),\n",
        "        StructField(\"heading_topic\", StructType([\n",
        "              StructField(\"id\", IntegerType(), True),\n",
        "              StructField(\"name\", StringType(), True),\n",
        "             ])),\n",
        "        StructField(\"name\", StringType(), True),\n",
        "    ])),\n",
        "StructField(\"statement\", StringType(), True)\n",
        "   ])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDPlrtsnoGut",
        "colab_type": "code",
        "outputId": "883b28cf-3744-4946-cde0-9beb83a3086b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "# Carregando o Json e Inferindo o Schema\n",
        "df_json = spark.read.option(\"multiLine\",True).json(\"data_question.json\",schema=schema_questions)\n",
        "\n",
        "# Verificando o Schema\n",
        "df_json.printSchema()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- answer_key: integer (nullable = true)\n",
            " |-- difficulty: string (nullable = true)\n",
            " |-- grade: long (nullable = true)\n",
            " |-- id: integer (nullable = true)\n",
            " |-- lecture: integer (nullable = true)\n",
            " |-- options: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- description: string (nullable = true)\n",
            " |    |    |-- id: integer (nullable = true)\n",
            " |-- properties: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- id: string (nullable = true)\n",
            " |    |    |-- key: string (nullable = true)\n",
            " |    |    |-- value: integer (nullable = true)\n",
            " |-- skill: struct (nullable = true)\n",
            " |    |-- code: long (nullable = true)\n",
            " |    |-- heading_topic: struct (nullable = true)\n",
            " |    |    |-- id: integer (nullable = true)\n",
            " |    |    |-- name: string (nullable = true)\n",
            " |    |-- name: string (nullable = true)\n",
            " |-- statement: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QinYPq-MotvC",
        "colab_type": "code",
        "outputId": "7c5f8b6b-4614-4c49-f3cb-5ef4edf46892",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "# Verificando o df_json\n",
        "df_json.show(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+----------+-----+---+-------+--------------------+--------------------+--------------------+--------------------+\n",
            "|answer_key|difficulty|grade| id|lecture|             options|          properties|               skill|           statement|\n",
            "+----------+----------+-----+---+-------+--------------------+--------------------+--------------------+--------------------+\n",
            "|         3|      EASY|    0|  0|      0|[[Government acco...|[[8f24467f-f351-4...|[5897001673776287...|Foreign while bas...|\n",
            "|         5|    MEDIUM|    0|  1|      0|[[France, Luxembo...|[[dd29752f-83ce-4...|[6712208284592011...|Machines designed...|\n",
            "|         5|    MEDIUM|    0|  2|      0|[[Is to interim p...|[[0761cdc8-b9ef-4...|[8179027570588556...|Esa to the predom...|\n",
            "|         1|      HARD|    0|  3|      0|[[A planetary Con...|[[4d8d5899-493c-4...|[7409025453606141...|The critique new ...|\n",
            "|         3|      EASY|    0|  4|      0|[[Bleues), Edgar ...|[[9ece5940-df29-4...|[7147975464900988...|Sheri killackeyal...|\n",
            "+----------+----------+-----+---+-------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Gu_8jurEgLv",
        "colab_type": "code",
        "outputId": "34b46b3c-b893-404a-da66-7571696bb7df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# Criando o dataframe Exame\n",
        "data_exam = [\n",
        "         {\n",
        "          'id': 0,\n",
        "          'tipo': 'Enem',\n",
        "          'ano': 2019,\n",
        "         },\n",
        "        {\n",
        "          'id': 1,\n",
        "          'tipo': 'Enem',\n",
        "          'ano': 2020,\n",
        "         },\n",
        "        {\n",
        "          'id': 2,\n",
        "          'tipo': 'Fuvest',\n",
        "          'ano': 2020,\n",
        "         },\n",
        "        {\n",
        "          'id': 3,\n",
        "          'tipo': 'Fuvest',\n",
        "          'ano': 2019,\n",
        "         },\n",
        "        {\n",
        "          'id': 4,\n",
        "          'tipo': 'uerj',\n",
        "          'ano': 2020,\n",
        "         }\n",
        "]\n",
        "\n",
        "# Criando o Schema para DataFrame Exame\n",
        "schema_exame = StructType([\n",
        "    StructField(\"id\", IntegerType(), True),\n",
        "    StructField(\"tipo\", StringType(), True),\n",
        "    StructField(\"ano\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "df_exam = spark.createDataFrame(data_exam, schema_exame)\n",
        "\n",
        "# Mostrando o df\n",
        "df_exam.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+------+----+\n",
            "| id|  tipo| ano|\n",
            "+---+------+----+\n",
            "|  0|  Enem|2019|\n",
            "|  1|  Enem|2020|\n",
            "|  2|Fuvest|2020|\n",
            "|  3|Fuvest|2019|\n",
            "|  4|  uerj|2020|\n",
            "+---+------+----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9OIEmJEEosM",
        "colab_type": "text"
      },
      "source": [
        "**TABELA 1**\n",
        "\n",
        "Criando o data frame que servirar para criar a Tabela1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rucaTBDcEsIM",
        "colab_type": "code",
        "outputId": "b8149e3c-d735-4e4e-c9c4-acc9ea7bebac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "# Importando as funções do pacote Sql para o tratamento dos dados\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Criando o primiro data frame para base das sontrução das futuras tabelas\n",
        "df_base = df_json.select(\n",
        "                      expr(\"id as question_id\"),\n",
        "                      expr(\"statement as question\"),\n",
        "                      expr(\"properties.id as properties_id\"),\n",
        "                      expr(\"properties.key  as properties_name\")\n",
        "                      )\n",
        "\n",
        "# Criando e Adicionando a Coluna calculada \"exam_id\" para se relacionar com df_exam\n",
        "df_0 = df_base.withColumn('exam_id',df_base['question_id'] % 5)\n",
        "\n",
        "#Juntando as Tabelas para a criação do data framae que se tornara a Tabela1 do solicitado no Teste\n",
        "df_1 = df_0.join(df_exam,df_0.exam_id == df_exam.id).drop(df_exam.id)\n",
        "\n",
        "# Ordenando e removendo a coluna ano \n",
        "tab1 = df_1.orderBy(\"question_id\").drop(df_1.ano)\n",
        "\n",
        "tab1.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+--------------------+--------------------+--------------------+-------+------+\n",
            "|question_id|            question|       properties_id|     properties_name|exam_id|  tipo|\n",
            "+-----------+--------------------+--------------------+--------------------+-------+------+\n",
            "|          0|Foreign while bas...|[8f24467f-f351-47...|[THE, MAL, THE, F...|      0|  Enem|\n",
            "|          1|Machines designed...|[dd29752f-83ce-45...|[THERÓN, BROO, OF...|      1|  Enem|\n",
            "|          2|Esa to the predom...|[0761cdc8-b9ef-43...|[INED, MODGES, CO...|      2|Fuvest|\n",
            "|          3|The critique new ...|[4d8d5899-493c-47...|[KM, TORLD, INABL...|      3|Fuvest|\n",
            "|          4|Sheri killackeyal...|[9ece5940-df29-49...|[BUIRLY, ANG, AK)...|      4|  uerj|\n",
            "|          5|Other tributary n...|[8b58e1b0-93b7-4d...|[FUNCEL, TOGRA,, ...|      0|  Enem|\n",
            "|          6|One-way movement....|[63a27710-6caa-4a...|[FORTMO, HAROPL, ...|      1|  Enem|\n",
            "|          7|Involved, or we o...|[7d146dbe-6d7f-41...|[IN, EIRTWE, AND,...|      2|Fuvest|\n",
            "|          8|Leibniz (1646–171...|[8a620e6f-78d6-4f...|[AK), BEIROU, IN,...|      3|Fuvest|\n",
            "|          9|Has evolved the s...|[f3a8e196-ff5e-4d...|[FOR, OTHE, WCL-9...|      4|  uerj|\n",
            "|         10|Air france, one's...|[ec34726b-c320-4c...|[ANG, OF, SO, 187...|      0|  Enem|\n",
            "|         11|Places consist a ...|[fb29b8a2-5527-4e...|[MAL, OF, HAVENT,...|      1|  Enem|\n",
            "|         12|Fun as usually pr...|[4e52dfec-c4bf-49...|[TETWEV, SHICAL, ...|      2|Fuvest|\n",
            "|         13|Western european ...|[5ba9accd-b345-4b...|[OF, ETED, HING, ...|      3|Fuvest|\n",
            "|         14|Living room small...|[97c55b21-f683-49...|[THEORY, AS, FOUN...|      4|  uerj|\n",
            "|         15|The case primaril...|[aeb40da9-d2bb-43...|[KNORME, BY, IT, ...|      0|  Enem|\n",
            "|         16|Personal persever...|[bb9d7fd4-da41-4f...|[W., ARK, TAT, AG...|      1|  Enem|\n",
            "|         17|Redrawn once the ...|[0fd789a9-fc7e-4f...|[ING,, OTHE, ASSI...|      2|Fuvest|\n",
            "|         18|Be solved sculptu...|[665df115-ea93-44...|[ANDERL, BESED, T...|      3|Fuvest|\n",
            "|         19|Science practice ...|[9e65fa93-9ee6-46...|[INTS, ISSIGH, RE...|      4|  uerj|\n",
            "+-----------+--------------------+--------------------+--------------------+-------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdwcd-pRE6kd",
        "colab_type": "text"
      },
      "source": [
        "**TABELA 2**\n",
        "\n",
        "Criando o data frame que servirar para criar a Tabela2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxBTiuFqE8Ij",
        "colab_type": "code",
        "outputId": "bce7819a-e56d-4721-99a5-af6fc7d791ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "# Agrupando a base de acordo com a quantidade de vezes que a propiedade caiu\n",
        "df_2 = df_1.groupby(\n",
        "                 expr('properties_id'),\n",
        "                 expr(\"properties_name\"),\n",
        "                 expr('exam_id'),expr('tipo'),\n",
        "                 expr('ano')\n",
        "                  ).agg(\n",
        "                count('properties_id')\n",
        "                .alias('properties_size')\n",
        "                 )\n",
        "#Organizando a sequencia das colunas\n",
        "tab2 = df_2.select(\"properties_id\",\"properties_name\",\"properties_size\",\"exam_id\",\"tipo\",\"ano\")\n",
        "\n",
        "tab2.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+---------------+-------+------+----+\n",
            "|       properties_id|     properties_name|properties_size|exam_id|  tipo| ano|\n",
            "+--------------------+--------------------+---------------+-------+------+----+\n",
            "|[93e00441-0796-49...| [LAT, BY, 4, PERTA]|              1|      0|  Enem|2019|\n",
            "|[c023203d-4b95-47...|       [IND, SUCTED]|              1|      0|  Enem|2019|\n",
            "|[a4b0bfa7-4ef2-43...|          [UN., LAW]|              1|      0|  Enem|2019|\n",
            "|[522dcd15-0968-43...|        [BEFUND, OF]|              1|      0|  Enem|2019|\n",
            "|[4aeeb7a5-2cc8-4a...|[WEACHA, DAYN, CA...|              1|      0|  Enem|2019|\n",
            "|[77be37cf-dcc9-42...|[OF, ITA, FORIVE,...|              1|      0|  Enem|2019|\n",
            "|[025d1f4e-3e4f-4c...|[MORDPA, NEUQUE, ...|              1|      0|  Enem|2019|\n",
            "|[87791be8-d26c-4e...|  [AS, ARST, CLAGAR]|              1|      0|  Enem|2019|\n",
            "|[22574ef3-518f-48...|        [DITINK, IS]|              1|      1|  Enem|2020|\n",
            "|[01e5cc4a-7776-4d...|[THE, AS, COVITI,...|              1|      1|  Enem|2020|\n",
            "|[05bc302d-96bb-48...|[MON\"., THE, ONE,...|              1|      1|  Enem|2020|\n",
            "|[1150c72a-1015-45...|[THE, THAVE,, 2,0...|              1|      1|  Enem|2020|\n",
            "|[ad765bbf-95a1-4c...|[TH, TWELD, SHIND...|              1|      1|  Enem|2020|\n",
            "|[0858f13f-21af-46...|            [SUCTED]|              1|      1|  Enem|2020|\n",
            "|[37b620ed-c982-47...|            [ABOVER]|              1|      1|  Enem|2020|\n",
            "|[15ab7a6d-d8f1-40...|      [ISLAN, PEORD]|              1|      2|Fuvest|2020|\n",
            "|[4caad3e9-649c-44...|[BROO, KM, TETWEV...|              1|      2|Fuvest|2020|\n",
            "|[0675b1e5-0076-4c...|[ING, NOMMOT, OF,...|              1|      2|Fuvest|2020|\n",
            "|[eab68254-83f5-44...|               [THE]|              1|      2|Fuvest|2020|\n",
            "|[c6ac0cc6-7354-49...|            [SLIALL]|              1|      2|Fuvest|2020|\n",
            "+--------------------+--------------------+---------------+-------+------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ok4TjQhGA2e",
        "colab_type": "text"
      },
      "source": [
        "#**Escrevendo as Tabelas no Hive**\n",
        "\n",
        "Como ja tinha estanciado no incio do script o contexto do Hive na Sessão do Spark então já posso criar direto as Tabelas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHA9eBiHFONt",
        "colab_type": "code",
        "outputId": "b4bc7af4-0fb0-4265-aae6-f88fce93dfdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "# Criando a Tabela1\n",
        "tab1.write.saveAsTable('Tabela1')\n",
        "\n",
        "# Lendo a Tabela1\n",
        "spark.sql(\"SELECT * FROM Tabela1\").show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+--------------------+--------------------+--------------------+-------+------+\n",
            "|question_id|            question|       properties_id|     properties_name|exam_id|  tipo|\n",
            "+-----------+--------------------+--------------------+--------------------+-------+------+\n",
            "|       1525|Solve specific su...|[5002eae8-14be-48...|[INTS, THE, ST, W...|      0|  Enem|\n",
            "|       1526|Main part poor te...|[3cbce0e1-590a-48...|[OF, CONS., LEAGE...|      1|  Enem|\n",
            "|       1527|Egypt web henry r...|[9cf00a98-b35c-46...|  [A, IT?, 695, THE]|      2|Fuvest|\n",
            "|       1528|Ivan albright and...|[84cd5fb4-2088-42...|[THED, SOLUDG, IN...|      3|Fuvest|\n",
            "|       1529|Ottawa, calgary, ...|[2c47ef6d-294f-49...|[FARE, TOR, REMON...|      4|  uerj|\n",
            "|       1530|Second republic n...|[10e50069-6d11-40...|[MONCH-, CREAL, E...|      0|  Enem|\n",
            "|       1531|Around mid-may de...|[23cf3fc3-a9f0-47...|[DAYN, BESED, THE...|      1|  Enem|\n",
            "|       1532|The geological ho...|[dfaf8a1e-2532-47...|[AS, LIND, ETHE, ...|      2|Fuvest|\n",
            "|       1533|(see inbreeding h...|[8c74c88f-1e93-4b...|[THED, AGENT,, WO...|      3|Fuvest|\n",
            "|       1534|Astronomy, partic...|[7587c18e-68f4-44...|[THE, CLOS., RE, ...|      4|  uerj|\n",
            "|       1535|(21): 3060. fame ...|[0efc4479-21e9-4b...|[FALLEC, GLIS, IN...|      0|  Enem|\n",
            "|       1536|Of hercules count...|[d79049f8-d20d-45...|[AN:, NALL, MAT, ...|      1|  Enem|\n",
            "|       1537|Molly on thought ...|[0f6ac457-f347-42...|[BY, INTURO, HAD,...|      2|Fuvest|\n",
            "|       1538|And mamie of 349,...|[49432ed6-e297-41...|[KELECU, TH'S, AR...|      3|Fuvest|\n",
            "|       1539|Space. because st...|[630247ad-9ccb-46...|[COMERN, MOUNDI, ...|      4|  uerj|\n",
            "|       1540|\"actors\" and they...|[4ba87611-d949-46...| [IS, EURE, VILY, A]|      0|  Enem|\n",
            "|       1541|Altitude level to...|[3b9efc57-69a1-49...|[OF, IS, INT,, FL...|      1|  Enem|\n",
            "|       1542|Everyday behavior...|[7bc50a2a-1a2d-46...|[ABOUTE, VOLIAL, ...|      2|Fuvest|\n",
            "|       1543|Study biological ...|[7e9e39ae-2824-47...|[CAND, IS, OTHE, ...|      3|Fuvest|\n",
            "|       1544|(wire services) s...|[42289c4c-6d59-46...|[ETED, THERST, 19...|      4|  uerj|\n",
            "+-----------+--------------------+--------------------+--------------------+-------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn2Om2qfGz-3",
        "colab_type": "code",
        "outputId": "fb42050d-aa85-4ad1-f56c-4b4d11da3f21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "# Criando a Tabela2\n",
        "tab2.write.saveAsTable('Tabela2')\n",
        "\n",
        "# Lendo a Tabela1\n",
        "spark.sql(\"SELECT * FROM Tabela2\").show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+---------------+-------+------+----+\n",
            "|       properties_id|     properties_name|properties_size|exam_id|  tipo| ano|\n",
            "+--------------------+--------------------+---------------+-------+------+----+\n",
            "|[fa398b5c-24d5-40...|     [WCL-93, PERTA]|              1|      0|  Enem|2019|\n",
            "|[9af924f5-a6de-40...|         [NUE, SOUT]|              1|      0|  Enem|2019|\n",
            "|[6b723293-60c0-4e...|[TH'S, UNTIMS, KN...|              1|      0|  Enem|2019|\n",
            "|[6924781d-aff5-4e...|[COVITI, RECING, ...|              1|      0|  Enem|2019|\n",
            "|[e101ade9-508d-49...|     [THER., POPLEN]|              1|      0|  Enem|2019|\n",
            "|[43037bb9-ccf4-48...|[HATION, TO, THE, A]|              1|      0|  Enem|2019|\n",
            "|[390bc16f-c039-41...|[WIDESS, AL, (SUS...|              1|      1|  Enem|2020|\n",
            "|[290d0ef1-9fe0-4d...|    [BEIROU, JOSPER]|              1|      1|  Enem|2020|\n",
            "|[1b5fdd61-3d2a-4b...|      [THEIRD, HANE]|              1|      1|  Enem|2020|\n",
            "|[680624e2-78a1-42...|               [THE]|              1|      1|  Enem|2020|\n",
            "|[438b3c6f-b292-42...| [TABLIZ, KING, SED]|              1|      1|  Enem|2020|\n",
            "|[cd33b9e6-f5ef-4a...|   [WASS, OF, ENTED]|              1|      1|  Enem|2020|\n",
            "|[ff7c4b4d-fe3a-4c...|   [198, TOGION, IN]|              1|      1|  Enem|2020|\n",
            "|[771f60ba-740c-4b...|        [WORK, HING]|              1|      2|Fuvest|2020|\n",
            "|[ec5368d1-d3cc-4c...|[TOR, RIVERS, THE...|              1|      2|Fuvest|2020|\n",
            "|[7e05160c-35e8-4c...|  [ST, THE, TE, OFT]|              1|      2|Fuvest|2020|\n",
            "|[f5d816de-c2f8-45...|[AR, QUE., FAL, THE]|              1|      2|Fuvest|2020|\n",
            "|[d0c5e343-ebbd-42...|[BUE, UN., POOD, ...|              1|      2|Fuvest|2020|\n",
            "|[e9500dc7-9ab7-44...|[ORE, CONTAL, SOL...|              1|      2|Fuvest|2020|\n",
            "|[1e0e852f-f896-43...|[MODE, THE, BESED...|              1|      2|Fuvest|2020|\n",
            "+--------------------+--------------------+---------------+-------+------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "482g7GK5UKj2",
        "colab_type": "text"
      },
      "source": [
        "#**Referencias**\n",
        "\n",
        "https://spark.apache.org/docs/latest/sql-data-sources.html\n",
        "https://sparkbyexamples.com/spark/spark-schema-explained-with-examples/\n",
        "https://cwiki.apache.org/confluence/display/Hive/AdminManual+Metastore+Administration\n",
        "https://creativedata.atlassian.net/wiki/spaces/SAP/pages/82255289/Pyspark+-+Read+Write+files+from+Hive"
      ]
    }
  ]
}